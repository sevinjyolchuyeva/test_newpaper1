{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import division,print_function\n",
    "\n",
    "\n",
    "import theano\n",
    "import keras\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, TimeDistributed,RepeatVector\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.optimizers import SGD,Adam\n",
    "from  data_processing import data_process\n",
    "from keras.layers import Dense,Input, Activation\n",
    "import keras\n",
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.layers import Convolution1D, MaxPooling1D,Flatten\n",
    "\n",
    "from  data_processing_fast import data_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this function calculates Phoneme error rate (PER)\n",
    "def per(r, h):\n",
    "    #build the matrix\n",
    "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8).reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        for j in range(len(h)+1):\n",
    "            if i == 0: d[0][j] = j\n",
    "            elif j == 0: d[i][0] = i\n",
    "    for i in range(1,len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitute = d[i-1][j-1] + 1\n",
    "                insert = d[i][j-1] + 1\n",
    "                delete = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitute, insert, delete)\n",
    "    result = float(d[len(r)][len(h)]) / len(r) * 100\n",
    "    return result\n",
    "\n",
    "# in below, I made my callbacks which after every epoch it calculates PER \n",
    "class My_Callback(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(keras.callbacks.Callback,self).__init__()\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "    \n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "    \n",
    "    def on_epoch_begin(self,epoch, logs={}):\n",
    "        return\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        x_validation=self.validation_data[0]\n",
    "        y_validation=self.validation_data[1]\n",
    "        y_validation=y_validation.reshape(y_validation.shape[0],maxlen,len_out)\n",
    "        pr=0\n",
    "        er_word=0\n",
    "        for i in range(x_validation.shape[0]):\n",
    "            x_test = np.array([x_validation[i, :, :]])\n",
    "            y_test = np.array([y_validation[i, :, :]])\n",
    "            y_pred = model.predict(x_test, verbose=0)\n",
    "            y_pred=y_pred.reshape(y_pred.shape[0],maxlen,len_out)\n",
    "\n",
    "            xtest_text = decode_text_i(x_test[0])\n",
    "            ytest_text = decode_text(y_test[0])\n",
    "            ypred_text = decode_text(y_pred[0])\n",
    "            if ypred_text not in ytest_text:\n",
    "                er_word=er_word+1\n",
    "            o,p = ytest_text.split(),ypred_text.split()\n",
    "            pr=pr+per(o,p)\n",
    "        \n",
    "        PER=pr/x_validation.shape[0]\n",
    "        WER=er_word/x_validation.shape[0]\n",
    "        logs['val_PER']=PER\n",
    "        logs['val_WER']=WER\n",
    "        print(' ')\n",
    "        print('val_PER: ', PER)\n",
    "        print(' ')\n",
    "\n",
    "       \n",
    "        \n",
    "        return    \n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "    \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        #self.losses.append(logs.get('loss'))\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text_i(probas):\n",
    "    text_seq = []\n",
    "    for i in range(probas.shape[0]):\n",
    "        idx = np.argmax(probas[i])\n",
    "        text_seq.append(indices_char_i[idx])\n",
    "    return \"\".join(text_seq).strip()\n",
    "\n",
    "def decode_text(probas):\n",
    "    text_seq = []\n",
    "    for i in range(probas.shape[0]):\n",
    "        idx = np.argmax(probas[i])\n",
    "        text_seq.append(indices_char_o[idx])\n",
    "        dec_text=\" \".join(text_seq).strip()\n",
    "        if indices_char_o[idx]=='/EP' :\n",
    "            break\n",
    "    return dec_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time =time.time()\n",
    "\n",
    "\n",
    "\n",
    "path1='training_input.txt'\n",
    "path2='training_output.txt'\n",
    "path3='test_input.txt'\n",
    "path4='test_output.txt'\n",
    "path5='dev_input.txt' # validation data\n",
    "path6='dev_output.txt'\n",
    "\n",
    "\n",
    "\n",
    "X,Y, Xdev,Ydev,Xtest,Ytest,maxlen,len_in,len_out,indices_char_o=data_process_fast(path1,path2,path3,path4,path5,path6)\n",
    "\n",
    "\n",
    "X=X.reshape(X.shape[0],X.shape[1],1).astype(\"float32\")\n",
    "Xtest=Xtest.reshape(Xtest.shape[0],Xtest.shape[1],1).astype(\"float32\")\n",
    "Xdev=Xdev.reshape(Xdev.shape[0],Xdev.shape[1],1).astype(\"float32\")\n",
    "Y=Y.reshape(Y.shape[0],-1).astype(\"float32\")\n",
    "Ydev=Ydev.reshape(Ydev.shape[0],-1).astype(\"float32\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "print ('Model')\n",
    "\n",
    "inp = Input((X.shape[1],X.shape[2]))\n",
    "cnv1 = Convolution1D(64, 3, border_mode='same')(inp)\n",
    "\n",
    "r1 = Residual(64, 128, cnv1)\n",
    "r2 = Residual(128, 256, r1)\n",
    "r3 = Residual(256, 512, r2)\n",
    "\n",
    "btc2 = BatchNormalization()(r3) \n",
    "act2 = Activation(\"relu\")(btc2)\n",
    "flat=Flatten()(act2)\n",
    "\n",
    "\n",
    "out= Dense(len_out*maxlen,activation='softmax') (flat)\n",
    "model = Model(input=inp, output=out)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_PER', patience=60, mode='min')\n",
    "filepath=\"residual_cnn_dep3.hd5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_PER', save_best_only=True,save_weights_only=True, mode='min')\n",
    "callbacks_list = [My_Callback(),early_stopping,checkpoint]\n",
    "model.fit(X, Y, validation_data=(Xdev, Ydev), batch_size=128, nb_epoch=100, callbacks=callbacks_list)\n",
    "model.load_weights(\"residual_cnn_dep3.hd5\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_word=0 #how many word is not correct\n",
    "phonem=0 \n",
    "for i in range(Xtest.shape[0]):  \n",
    "    x_test = np.array([Xtest[i, :, :]])\n",
    "    y_test = np.array([Ytest[i, :, :]])\n",
    "    y_pred = model.predict(x_test, verbose=0)\n",
    "    y_pred=y_pred.reshape(y_pred.shape[0],maxlen,len_out)\n",
    "    ytest_text = decode_text(y_test[0])\n",
    "    ypred_text = decode_text(y_pred[0])\n",
    "    \n",
    "    print(\"expected: [%s], got: [%s] \" % \n",
    "    ( ytest_text, ypred_text))\n",
    "         \n",
    "    if ypred_text not in ytest_text:\n",
    "        er_word=er_word+1\n",
    "    o,p = ytest_text.split(),ypred_text.split()\n",
    "    phonem=phonem+per(o,p)\n",
    "\n",
    "\n",
    "print('how many words are wrong: ', er_word )\n",
    "print('Phoneme error rate:', phonem/Xtest.shape[0])\n",
    "print('Word error rate:',  er_word/Xtest.shape[0])\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
